{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Estadística Inferencial: probabilidades y tipos de muestreo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Introducción a la estadística inferencial\n",
    "Objetivo de la estadística inferencial: obtención de generalizaciones estadísticas sobre una población determinada a partir del estudio de las características de una muestra extraída de dicha población o universo.\n",
    "\n",
    "En realidad el campo de la estadística descriptiva no difiere en sus técnicas del campo de la estadística inferencial. La diferencia entre ambos campos estriba en la manera de utilizar tales técnicas. Si las técnicas se utilizan tan sólo para resumir datos, se dice entonces que se trata de técnicas descriptivas. Si se utlizan para estimar parámetros de una población a partir de los cálculos realizados con los datos de una muestra, entonces se trata de técnicas inferenciales.\n",
    "\n",
    "Población $ \\to $  Parámetros\n",
    "\n",
    "Muestra  $ \\to $ Estadísticos\n",
    "\n",
    "Por lo general, las letras griegas se utilizan para refererise a características de la población, mientras que las letras del abecedario latino se emplean con las características muestrales.\n",
    "\n",
    "Los **parámetros** que son valores fijos de la población, suelen desconocerse. Los **estadísticos**, que varían de muestra a muestra, se utilizan para estimar los parámetros. El proceso de estimación, eje de la estadística inferencial, se basa en la teoría de las probabilidades y en la teoría del muestreo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Probabilidad: nociones básicas y definición\n",
    "La *probabilidad matemática*, y las leyes del azar, se refieren tan sólo a sucesos repetidos bajos condiciones determinadas y constantes. Se refiere al resultado medio de un gran número de apariciones u ocurrencias de un suceso.\n",
    "\n",
    "Cuando llega el momento de determinar prácticamente la probabilidad de un determinado suceso sólo existen dos métodos disponibles: \n",
    "\n",
    "- **apriorístico**: definición clásica de probabilidad. \n",
    "    \n",
    "La probabilidad a priori de ocurrencia del suceso A es el cociente entre el número de casos favorables y el número de casos posibles (esta definición supone que todos los casos sean igualmente probables).\n",
    "\n",
    "$$ P(A) = \\frac{a}{n} $$\n",
    "\n",
    "La determinación de la probabilidad se basa en el conocimiento previo de las probabilidades de tales sucesos. Razonamiento circular.\n",
    "\n",
    "- **empírico**: Se basan en el supuesto de que la proporción de aparición de los sucesos observada en el pasado persistirá en el futuro.\n",
    "\n",
    "Las probabilidades empíricas son tan sólo estimaciones de las *probabilidades verdaderas*, pero cuanto mayor sea el número total de casos observados más precisa será la estimación.\n",
    " \n",
    "### Propiedades matemáticas de las probabilidades empíricas de un suceso\n",
    "1. La **probabilidad de un suceso** no puede ser mayor a la unidad ni menor a cero. $$ 0 \\leq P(A) \\leq 1 $$\n",
    "\n",
    "\n",
    "2. **Regla de la adición**: si los sucesos A y B son mutuamente excluyentes, la probabilidad de obtener A o B es igual a la probabilidad de A más la probabilidad de B. $$ P(A  \\veebar B) = P(A) + P(B) $$\n",
    "\n",
    "\n",
    "3. **Regla de la multiplicación**: si A y B son dos sucesos cualesquiera, la probabilidad de obtener simultáneamente A y B es igual a la probabilidad de obtener uno de ambos sucesos multiplicada por la probabilidad condicional de obtener el otro suceso una vez que ha ocurrido el primero. $$ P (AB) = P(A) P(B/A) = P(B) P(A/B) $$\n",
    "\n",
    "\n",
    "Siempre que tratemos una secuencia de sucesos a lo largo del tiempo y se calculan las probabilidades de su ocurrencia conjunta, tenemos procesos estocásticos. Una forma especial de proceso estocástico viene dada por las llamadas [cadenas de Markov](https://es.wikipedia.org/wiki/Cadena_de_M%C3%A1rkov). \n",
    "\n",
    "### Combinatoria y probabilidad\n",
    "En la determinación de las prioridades *a priori* se ha supuesto que los diversos sucesos eran igualmente probables. Se hace necesario aplicar reglas matemáticas que nos den directamente el número de secuencias en que se pueden distribuir los sucesos favorables y posibles.\n",
    "\n",
    "### Variaciones y permutaciones\n",
    "Las **variaciones** se refieren a los distintos grupos que se pueden formar con *m* elementos tomados de *n* en *n* (siendo *n* < *m*), con la condición de que dos grupos serán distintos si difieren en el orden o en la naturaleza de sus elementos.\n",
    "$ V_{m,n} = \\frac {m!}{(m-n)!} $\n",
    "\n",
    "**Variaciones con repetición** \n",
    "$ V_{m,n} = m^n $\n",
    "\n",
    "**Variaciones con permutaciones** (los grupos varían tan solo en el orden de los elementos que los integran).\n",
    "$ P_{n,n} = n! $\n",
    "\n",
    "** Permutaciones con repetición** (en los grupos se repiten algunos de los elementos).\n",
    "$ PR_n = \\frac {n!}{n_1! n_2! ... n_k!} $\n",
    "\n",
    "### Combinaciones\n",
    "Podemos estar interesados en obtener grupos que sólo difieran entre sí por la naturaleza de los elementos (exclusivamente): *combinaciones*.\n",
    "$ C_{m,n} = \\binom{m}{n} = \\frac {m!}{n! (m - n)!} $\n",
    "\n",
    "Algunas combinaciones particulares:\n",
    "- $ \\binom{n}{0} = 1 $\n",
    "- $ \\binom{n}{1} = n $\n",
    "- $ \\binom{n}{2} = n(n-1)/2 $"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Aspectos generales del muestreo en la investigación sociológica\n",
    "Las poblaciones no resultan directamente asequibles de modo que hay que recurrir al *muestreo* para permitir hacer generalizaciones seguras acerca de las poblaciones. \n",
    "\n",
    "Diversas son las ventajas que ofrece el uso de muestras: reducción de los costes, mayor rápidez y el logro de unos datos más comprensivos (a veces un buen plan de muestreo ofrece mejores estimaciones de los valores que el propio Censo de la población -esto debido a la magnitud de los *errores no muestrales*).\n",
    "\n",
    "Siempre que sea posible se ha de preferir el muestreo aleatorio, ya que sólo en una muestra de este tipo se puede calcular un intervalo de confianza dentro del que se encuentran, con un nivel de probabilidad dado, los parámetros del universo. Además el muestreo aleatorio simple sirve como modelo a partir del que se han derivado el resto de las técnicas muestrales aleatorias.\n",
    "\n",
    "La característica que distingue a una muestra probabilística es que cada individuo debe tener una *probabilidad conocida* de poder ser incluido en la muestra. De esta manera, se pueden realizar legitimamente inferencias estadísticas.\n",
    "\n",
    "### Tipos de muestreo\n",
    "\n",
    "- Muestreo Aleatorio Simple\n",
    "    - **Con reposición**. El número posible de muestras es $ M^n $.\n",
    "    - **Sin reposición**. El número posible de muestras viene dado por  $ \\binom{M}{n} = \\frac{M!}{(M-n)! n!} $\n",
    "\n",
    "### Estimadores y errores de muestreo\n",
    "Dado que el estimador *p* ha sido calculado en base a las *n* unidades de la muestra, en lugar de las *N* unidades que constituyen la población, su valor estará afectado por un error que se denomina *error de muestreo*. Cada muestra de tamaño *n* que se extraiga de la población *N* dará una proporci´no *p* diferente de la anterior. Como el número de muestras sin reposición que se pueden obtener es $ $ \\binom{N}{n} $, este será también el número de los posibles estimadores de *p*. Pues bien, el error de muestreo es la desviación típica de todos esos posibles valores de *p*.\n",
    "\n",
    "La estimación del error de muestreo se realiza utilizando los valores de la muestra, por medio de la fórmula: \n",
    "$$ \\sqrt{\\frac{N - m}{N} * \\frac{pq}{n - 1}} $$\n",
    "\n",
    "A partir de la estimación del error de muestreo se pueden determinar los *intervalos de confianza*, que son intervalos del tipo $ (p - zs, p + zs) $\n",
    "### Determinación del tamaño de la muestra\n",
    "Se ha de utilizar la muestra que mejor represente el universo de trabajo con los medios materiales y económicos de que dispone el investigador.\n",
    "\n",
    "A partir, pues, del conocimiento del error absoluto prefijado, el margen de probabilidad deseado y el valor de *p*, es posible determinar el tamaño *n* de la muestra en una población de tamaño N conocido.\n",
    "\n",
    "El hecho de que el intervalo de confianza *p+zs* contenga el valor *p* que tratamos de estimar, con un cierto nivel de probabilidad, equivale a decir que la diferencia en avalor absoluto entre *P* y su estimación muestral *p* es menor o igual que $ z * s = E $, siendo *E* una cota de error absoluto especificada.\n",
    "\n",
    "Haciendo que $ n \\cong = n - 1 $, ya que, para tamaños altos de *n*, la sustracción no va a alterar prácticamente el valor de *n*, tendremos que:\n",
    "$$ n = \\frac{z^2Npq}{NE^2+z^2pq} $$\n",
    "\n",
    "Queda claro que en la determinación de *n* interviene mínimamente el valor de *N*.\n",
    "\n",
    "### Otros tipos de muestreo probabilístico\n",
    "\n",
    "### Muestreo no probabilístico"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}