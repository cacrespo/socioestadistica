{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadística descriptiva bivariable: características de una asociación bivariable\r\n",
    "Nos adentramos un poco más en las condiciones que influyen en la distribución de una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Total</th>\n      <th>Muy católicos</th>\n      <th>Practicantes</th>\n      <th>No muy practicantes</th>\n      <th>No practicantes</th>\n      <th>Indiferentes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Izquierda</th>\n      <td>18</td>\n      <td>5</td>\n      <td>8</td>\n      <td>16</td>\n      <td>34</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>Centro</th>\n      <td>38</td>\n      <td>30</td>\n      <td>43</td>\n      <td>35</td>\n      <td>37</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>Derecha</th>\n      <td>22</td>\n      <td>39</td>\n      <td>26</td>\n      <td>18</td>\n      <td>11</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>NsNc</th>\n      <td>21</td>\n      <td>26</td>\n      <td>23</td>\n      <td>21</td>\n      <td>18</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "           Total  Muy católicos  Practicantes  No muy practicantes  \\\nIzquierda     18              5             8                   16   \nCentro        38             30            43                   35   \nDerecha       22             39            26                   18   \nNsNc          21             26            23                   21   \n\n           No practicantes  Indiferentes  \nIzquierda               34            52  \nCentro                  37            28  \nDerecha                 11             6  \nNsNc                    18            14  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribución porcentual bivariable\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "datos_pct = {\r\n",
    "            'Total': [18, 38, 22, 21],\r\n",
    "            'Muy católicos': [5, 30, 39, 26],\r\n",
    "            'Practicantes': [8, 43, 26, 23],\r\n",
    "            'No muy practicantes': [16, 35, 18, 21],\r\n",
    "            'No practicantes': [34, 37, 11, 18],\r\n",
    "            'Indiferentes': [52, 28, 6, 14]\r\n",
    "            }\r\n",
    "df = pd.DataFrame(datos_pct, index = ['Izquierda', 'Centro', 'Derecha', 'NsNc'])\r\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general se sigue la convención de situar la variable dependiente, cuando la hubiere, en las filas, y la variable independiente en las columnas.\r\n",
    "\r\n",
    "¿Qué comparación debe facilitarse a a hora de calcular porcentajes? Existe una regla sencilla, universalmente aceptada: los porcentajes deben calcularse en el sentido del factor _causal_ o de la **_variables independiente_**.\r\n",
    "\r\n",
    "La diferencia entre porcentajes de columnas se conoce como **_epsilón_ ($ \\epsilon $)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Izquierda     3\nCentro       13\nDerecha     -13\nNsNc         -3\ndtype: int64"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ej. epsilon\r\n",
    "\r\n",
    "df['Practicantes'] - df['Muy católicos']\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Características de una asociación de dos variables\r\n",
    "\r\n",
    "Se puede caracterizar la relación entre dos variables mediante el estudio de las siguientes características:\r\n",
    "1. **existencia** o no de una asociación\r\n",
    "2. la **fuerza** de la asociación\r\n",
    "3. la **dirección** de la asociación\r\n",
    "4. la **naturaleza** de la asociación\r\n",
    "\r\n",
    "Existe una **asociación** entre dos variables cuando las correspondientes distribuciones condicionales porcentuales difieren en mayor o menor grado entre sí. Cuando hay asociación entre dos variables, la mayor parte de los _epsilón_ calculados al comparar las diferentes categorías son diferentes de cero.\r\n",
    "\r\n",
    "Otra forma de decir si existe asociación entre dos variables consiste en comparar las _frecuencias observadas_ en la tabla con las frecuencias que cabría eseperar si no existiera asociación, o _frecuencias esperadas_.\r\n",
    "\r\n",
    "$$ f_{eij} =  \\frac{n_i * n_j}{N} $$\r\n",
    "\r\n",
    "donde $ f_{eij} $ representa la frecuencia esperada de la celda correspondiente a la fila _i_ y la columna _j_ de la tabla; $n_i$ es el total para la fila _i_, y $n_j$ es el total para la columna _j_, siendo _N_ el número total de casos.\r\n",
    "\r\n",
    "La comparación se realiza restando el valor esperado de cada celdilla del valor observado de la celdilla correspondiente. Este valor se denomina _delta_.\r\n",
    "$$ \\delta = f_o - f_e $$\r\n",
    "\r\n",
    "Si todos los _deltas_ son cero, entonces existe _independencia estadística_ entre las dos variables.\r\n",
    "\r\n",
    "Cuando los valores epsilón o delta son elevados cabe hablar de una **fuerte** asociación entre las variables.\r\n",
    "\r\n",
    "Por lo que se refiere a la **dirección** de la asociación, sólo cabe hablar de ella cuando las variables se han medido, cómo mínimo, a nivel ordinal. Cuando la tendencia de variación conjunta de las dos variables es a que los valores altos de una variable se correspondan con los valores altos de la segunda variable, cabe hablar de la existencia de una _asociación positiva_. Caso contrario se dice entonces que la _asociación es negativa_.\r\n",
    "\r\n",
    "Por último, la **naturaleza** de una asociación se refiere a la forma general en que se distribuyen los datos en la tabla. Por ej. puede producirse una asociación _lineal_, _curvilinea_, o de otra naturaleza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La obtención de medidas de asociación entre dos variables: independencia estadística y asociación perfecta\r\n",
    "\r\n",
    "El investigador necesita disponer de medidas estandarizadas para poder comparar los valores obtenidos en diferentes tablas. Estas medidas suelen ser simples proporciones o cocientes (_ratios_) que son sensibles a los cambios que se producen en el grado de asociación y, en algunos casos, en la dirección y la naturaleza de la misma.\r\n",
    "\r\n",
    "Una medida sencilla que se puede crear a partir de los valores $\\delta$, o diferencias entre los valoers observados y esperados se denomina _chi-cuadrado_:\r\n",
    "$$ \\chi^2 = \\displaystyle\\sum \\left(\\frac{\\delta^2}{f_e}\\right) $$\r\n",
    "\r\n",
    "Este índice se utiliza más en la estadística inferencial, para la prueba de hipótesis, que en la estadística descriptiva (debido a algunas limitaciones que posee). Sin embargo, al tener una «distribución libre», se convierte en una prueba muy útil para variables nominales y ordinales.\r\n",
    "\r\n",
    "El coeficiente chi-cuadrado es siempre un número positivo, y se hace cero en las tablas en las que no hay asociación entre las variables. Sin embargo, el límite superior no es fijo, sino que vale $N ( K - 1)$, en donde _N_ es el tamaño de la muestra y _K_ es el número de filas o columnas en la tabla (el más chico).\r\n",
    "\r\n",
    "Otros coeficientes basados en chi-cuadrado tratan de aprovechar las ventajas que ofrece, a la vez que tratan de superar, mediante determinadas correcciones, sus deficiencias o limitaciones.\r\n",
    "\r\n",
    "**_fi-cuadrado ($\\phi^2$)_**:\r\n",
    "$$ \\phi^2 = \\frac{\\chi^2}{N} $$\r\n",
    "\r\n",
    "Presenta el inconveniente de que en tablas que contengan más de dos categorías en cada variable, el valor máximo de fi sobrepasa la unidad.\r\n",
    "\r\n",
    "**_C de Pearson (coeficiente de contingencia)_** grande Karl Pearson (1857-1936)! :smile:\r\n",
    "$$ C = \\sqrt{\\frac{\\chi^2}{\\chi^2 + N}} $$\r\n",
    "\r\n",
    "Nunca alcanza exactamente la unidad aunque hubiera asociación perfecta.\r\n",
    "\r\n",
    "**_T de Tschruprow_**\r\n",
    "$$ T = \\sqrt{\\frac{\\chi^2}{\\N(df)}} $$\r\n",
    "\r\n",
    "El límite superior de _T_ vale la unidad, con independencia del tamaño de la tabla, en tanto que ésta sea cuadrada. Ahora bien, para tablas que no son cuadradas, el valor de _T_ no puede alcanzar la unidad.\r\n",
    "\r\n",
    "**_V de Cramer_**\r\n",
    "$$ V = \\sqrt{\\frac{\\chi^2}{\\N * t}} $$ \\\\ t representa el valor más pequeño de las dos cantidades: n - 1 o m - 1 (siendo n y m el número de filas y columnas $$\r\n",
    "\r\n",
    "Siempre puede alcanzar el límite superior de la unidad, con independencia del tamaño de la tabla, y vale cero cuando no existe asociación alguna.\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "name": "python386jvsc74a57bd0ac824d9314dcf3e3ec65ce98774119415516c06c800c55d596a680dfe4488604"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac824d9314dcf3e3ec65ce98774119415516c06c800c55d596a680dfe4488604"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}