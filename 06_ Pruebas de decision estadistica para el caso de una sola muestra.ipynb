{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas de decisión estadística para el caso de una sola muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "Las pruebas estadísticas de este tipo generalmente informan si la muestra bajo estudio pertenece a una población determinada o no. En último término, contrastar los valores observados de una sola variable en una muestra en relación a los valores que toma dicha variable en la población. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La distribución binomial. La prueba binomial\r\n",
    "\r\n",
    "Existen poblaciones formadas tan sólo por dos categorías ($P$ y $Q$).\r\n",
    "\r\n",
    "La *distribución binomial* es la distribución muestral de las proporciones que se pueden observar en muestras aleatorias extraídas de una población que se caracteriza por estar compuesta por dos categorías de casos. La prueba binomial, al ser una prueba que mide la bondad del ajuste, nos dice si cabe esperar que las proporciones que se observan en una muestra puede pertenecer a una población que tiene un valor específico de $ P $.\r\n",
    "\r\n",
    "$$ p(x) = \\binom{N}{x}P^xQ^{n-x} $$\r\n",
    "donde:\r\n",
    "$$ \\binom{N}{x} = \\frac{N!}{x!(N-x)!}$$\r\n",
    "\r\n",
    "Por lo que se refiere a la forma de la distribución binomial, esta depende de los valores que tomen $ N $ y $ P $. Cuando $ P = Q = 0.5 $, la distribución será simétrica, y cuando $ N $ tiende al infinito, la distribución binomial tiende a aproximarse a la distribución normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11574074074074076\n",
      "0.11574074074074078\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.9837962962962963"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lanzamos un dado 4 veces y queresmos saber la probabilidad de que en dos lanzamientos salga 5.\r\n",
    "\r\n",
    "N = 4\r\n",
    "x = 2\r\n",
    "P = 1/6\r\n",
    "Q = 5/6\r\n",
    "\r\n",
    "a = (N * 3 * 2 * 1) / ((x * 1) * (N - x))\r\n",
    "b = P**2\r\n",
    "c = Q**(N-x)\r\n",
    "print(a*b*c)\r\n",
    "\r\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html#scipy.stats.binom\r\n",
    "from scipy.stats import binom\r\n",
    "print(binom.pmf(x, N, P))\r\n",
    "\r\n",
    "# distribución acumulada P <=2\r\n",
    "binom.cdf(x, N, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La prueba de chi-cuadrado ($\\chi^2$) para una sola muestra\r\n",
    "\r\n",
    "La técnica ($\\chi^2$) es del tipo de las que miden la bondad del ajuste cuando se dispone del *número observado* de respuestas y el *número esperado* basado en la hipótesis nula. La prueba mide la existencia o no de una diferencia significativa entre ambas frecuencias. Cuanto mayor sea el valor de ($\\chi^2$), mayor será la probabilidad de que las frecuencias observadas no provengan de la población en la que se basa la hipotesis nula.\r\n",
    "\r\n",
    "$$ \\chi^2 = \\displaystyle\\sum_{i=1}^{K} \\frac{(0_i - E_i)^2}{E_i} $$\r\n",
    "\r\n",
    "Para cada valor de *df* (grados de libertad) existe un valor diferente de chi-cuadrado. El valor de *df* refiere al mínimo de observaciones que pueden variar libremente después de haber establecido determinadas restricciones inherentes a la propia naturaleza de los datos.\r\n",
    "\r\n",
    "Algunos autores señalan el requisito de que cada frecuencia esperada debe ser al menos 5 para poder calcular $ \\chi^2 $\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5542980767282772\n",
      "0.9999999998919997\n"
     ]
    }
   ],
   "source": [
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html\r\n",
    "from scipy.stats import chi2\r\n",
    "\r\n",
    "# Valor de chi cuadrado para 5 grados de libertad y probabilidad 0.99 (1 - 0.01)\r\n",
    "df = 5\r\n",
    "print(chi2.ppf(0.01, df))\r\n",
    "\r\n",
    "# Probabilidad para valor de chi cuadrado 55.4 con 5 grados de libertad (función inversa a la anterior)\r\n",
    "print(chi2.cdf(55.4, df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones muestrales de las medias\r\n",
    "\r\n",
    "Al calcular las medias de todas las muestras del mismo tamaño extraídas de una población se obtiene una **distribución muestral** de las medias. La medida del error muestral que indica la magnitud de las desviaciones de los estadísticos de la muestra alrededor de sus respectivos parámetros se denomina **error típico**. Pues bien, el error típico de la media es una medida de la variabilidad de las medias de las muestras, alrededor de la media de la población. Mientras la **desviación típica** mide la variabilidad de los valores alrededor de su media, el error típico de la media mide la variabilidad de las medias muestrales alrededor de la media de la población.\r\n",
    "\r\n",
    "El valor del error típico se puede interpretar de la misma forma que la desviación típica.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6448536269514729\n"
     ]
    },
    {
     "data": {
      "text/plain": "8.660254037844387"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicio\r\n",
    "\r\n",
    "# Población normal, media: 60.000, sd = 20.000, x = 70.000, alfa = 0.05, n = 300\r\n",
    "\r\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\r\n",
    "from scipy.stats import norm\r\n",
    "\r\n",
    "# La región crítica viene determinada por la distribución normal = 1.65\r\n",
    "print(abs(norm.ppf(0.05,0,1)))\r\n",
    "\r\n",
    "# Calculamos varianza de la distribución muestral (que no es igual a la de la población que viene dada en el enunciado)\r\n",
    "\r\n",
    "s = 20000 / (300**(1/2))\r\n",
    "\r\n",
    "z = (70000 - 60000) / s\r\n",
    "\r\n",
    "z # Es mucho más grande que el valor crítico. Se rechaza hipótesis nula.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No siempre podemos trabajar con la desviación típica de la población (por la sencilla razón de que se desconoce). Una posible solución es sustituir la desviación típica de la población $\\sigma$ por la desviación típica de la muestra $s$. En la fórmula de $z$ podemos sustituir el cociente por: $$ \\frac{s}{\\sqrt{N}} $$\r\n",
    "Esta sustitución ofrece resultados razonables cuando el tamaño de la muestra es suficientemente grande. En caso de contar con una muestra pequeña se puede utilizar una prueba estadística alternativa llamada **$ t $ de Student**:\r\n",
    "$$ t = \\frac{\\overline{X} - \\mu} {s / \\sqrt{N - 1}} $$\r\n",
    "\r\n",
    "Para el caso de $t$, el numerador y el denominador son variables aleatorias porque $s$ es un estadístico en lugar de un parámetro. Cuando $ N $ es suficientemente grande (100 o más), $t$ es aproximadamente igual a $z$, ya que mayor es la aproximación de $s$ a $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7291328115213678 -3.487119154832539\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio\r\n",
    "\r\n",
    "# 20 cursos. Media 65/100. Últimos dos años media 57/100 con sd 10/100.\r\n",
    "\r\n",
    "df = 20 - 1\r\n",
    "alfa = 0.05\r\n",
    "\r\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html\r\n",
    "from scipy.stats import t\r\n",
    "\r\n",
    "# ppf(q, df, loc=0, scale=1)\r\n",
    "# Percent point function (inverse of cdf — percentiles).\r\n",
    "\r\n",
    "t_critic = t.ppf(alfa, df, loc=0, scale=1) \r\n",
    "\r\n",
    "## Calculate the t-statistics\r\n",
    "t = (57 - 65) / (10 / 19**(1/2))\r\n",
    "\r\n",
    "print(t_critic, t)\r\n",
    "\r\n",
    "# Como el t obtenido es mayor se rechaza hipótesis nula. El nivel académico ha sufrido un descenso significativo.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación puntual y por intervalo de parámetros\r\n",
    "Con frecuencia hay que estimar parámetros de la población por su relevancia teórica y práctica. Además, a veces la prueba de hipótesis no es posible en la resolución de problemas prácticos, sencillamente porque no es posible especificar el valor hipotético del parámetro.\r\n",
    "\r\n",
    "> La prueba de significación tal como se usa corrientemente en las ciencias de la conducta es inferencia estadística de baja calidad, y que incluso la buena inferencia estadística en la investigación básica es corrientemente sólo una forma conveniente de dejar de lado, en lugar de resolver, el problema de la inferencia científica.\r\n",
    ">\r\n",
    ">  *The Significance Test Controversy*, Morrison y Denkel, 1970\r\n",
    "\r\n",
    "Tenemos dos tipos básicos de estimación:\r\n",
    "- Estimación puntual\r\n",
    "- Estimación por intervalo\r\n",
    "\r\n",
    "Una ventaja de la estimación por intervalo es que la amplitud del intervalo indica la bondad de la eficiencia de la estimación. Otra ventaja es que se puede adscribir una probabilidad determinada a la estimación.\r\n",
    "\r\n",
    "### Intervalo de proporciones. Intervalos de confianza\r\n",
    "\r\n",
    "Para realizar una estimación por intervalo de una proporción se necesita conocer la tendencia central, variabilidad y forma de la distribución muestral de las proporciones.\r\n",
    "\r\n",
    "Una vez conocida la proporción (o la media) $p$ de la muestra, podemos estimar la proporción $P$ de la población, dado que aquella es un estimador no *sesgado* de ésta. Se dice que una estimación no está sesgada cuando su distribución muestral es exactamente igual al valor del parámetro que se ha estimado. Esto es, el valor esperado de la estimación a la larga es el propio parámetro.\r\n",
    "\r\n",
    "Cuando se conoce la proporción $P$ de la población, el error típico se calcula: $$ \\sigma_p = \\sqrt{PQ / N} $$\r\n",
    "Cuando no se conoce la proporción $P$: $$ s_p = \\sqrt{pq / N} $$\r\n",
    "Conocidos pues $p$ y $s_p$, juntos con los correspondientes valores típicos de $z$, se pueden conocer los límites de confianza.\r\n",
    "$$ lc = p \\pm z(s_p) $$\r\n",
    "En un intervalo de confianza se contiene una prueba implícita para cada posible valor del parámetro. La hipótesis alternativa se establece de forma que el valor del parámetro que se desea estimar quede dentro del intervalo de confianza para el nivel de probabilidad elegido.\r\n",
    "\r\n",
    "### Estimación de medias\r\n",
    "De igual modo que se ha hecho en el punto anterior, la estimación puntual de medias puede trasnformarse en una estimación por intervalo de tales parámetros. Cuando $N$ es suficientemente grande, la distribución apropiada es la distribución normal:\r\n",
    "$$ lc = \\overline{X} \\pm z(s_\\overline{x}) $$\r\n",
    "Cuando el tamaño de $N$ es pequeño y se desconoce la desviación típica $\\sigma$, la distribución muestral de la media no es normal. En tal caso se sigue la distribución $t$ de Student con $N-1$ grados de libertad:\r\n",
    "$$ lc = \\overline{X} \\pm t(s_\\overline{x}) $$\r\n",
    "\r\n",
    "### Determinación del tamaño de la muestra\r\n",
    "La fórmula que recoge el cálculo de los límites de confianza para la estimación de un parámetro puede servirnos también para calcular el tamaño de la muestra. Si contamos con:\r\n",
    "- el nivel de confianza que queremos utilizar ($z$)\r\n",
    "- el grado de exactitud con el que deseamos estimar ($e$)\r\n",
    "- una estimación razonable de los valores de los parámetros (conjetura para establecer $\\sigma$)\r\n",
    "\r\n",
    "Ya podemos calcular el tamaño:\r\n",
    "$$ \\overline{X} \\pm z \\sigma / \\sqrt{n} $$\r\n",
    "$$ z \\sigma / \\sqrt{n} = e $$\r\n",
    "$$ \\sqrt{n} = z \\sigma / e $$\r\n",
    "$$ n = \\sqrt{z \\sigma / e} $$\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.03742603053512872"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejercicios\r\n",
    "\r\n",
    "# 2.  Jóvenes y población de españa. Nivel de significancia 0,01 (X2 13,277)\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html\r\n",
    "from scipy.stats import chi2_contingency\r\n",
    "\r\n",
    "data = {'Muy partidario':  [3, 3],\r\n",
    "        'Bastante partidario': [10, 10],\r\n",
    "        'Poco partidario': [15, 19],\r\n",
    "        'Nada partidario': [42, 56],\r\n",
    "        'No sabe': [30, 12]\r\n",
    "        }\r\n",
    "\r\n",
    "tabla = pd.DataFrame (data)\r\n",
    "chi2_contingency(tabla)[1]\r\n",
    "\r\n",
    "# El valor de p es mayor a 0,01. No es significativa la diferencia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac824d9314dcf3e3ec65ce98774119415516c06c800c55d596a680dfe4488604"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}